{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('Iris.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data.drop(['Species'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data['Species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder=LabelEncoder()\n",
    "y=encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "x_train=sc.fit_transform(x_train)\n",
    "x_test=sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann=tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=2,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=1,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py:22: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(3, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2894 - loss: 0.0000e+00       \n",
      "Epoch 2/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - accuracy: 0.2197 - loss: 0.0000e+00  \n",
      "Epoch 3/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2757 - loss: 0.0000e+00     \n",
      "Epoch 4/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2812 - loss: 0.0000e+00 \n",
      "Epoch 5/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3432 - loss: 0.0000e+00 \n",
      "Epoch 6/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3400 - loss: 0.0000e+00 \n",
      "Epoch 7/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - accuracy: 0.3524 - loss: 0.0000e+00\n",
      "Epoch 8/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - accuracy: 0.2832 - loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.3480 - loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2606 - loss: 0.0000e+00 \n",
      "Epoch 11/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3342 - loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - accuracy: 0.3038 - loss: 0.0000e+00   \n",
      "Epoch 13/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - accuracy: 0.3269 - loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3078 - loss: 0.0000e+00 \n",
      "Epoch 15/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - accuracy: 0.3536 - loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3525 - loss: 0.0000e+00 \n",
      "Epoch 17/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 0.2804 - loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - accuracy: 0.3817 - loss: 0.0000e+00   \n",
      "Epoch 19/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - accuracy: 0.3154 - loss: 0.0000e+00   \n",
      "Epoch 20/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3228 - loss: 0.0000e+00 \n",
      "Epoch 21/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2610 - loss: 0.0000e+00     \n",
      "Epoch 22/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3680 - loss: 0.0000e+00 \n",
      "Epoch 23/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 0.3523 - loss: 0.0000e+00\n",
      "Epoch 24/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.2697 - loss: 0.0000e+00   \n",
      "Epoch 25/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2935 - loss: 0.0000e+00 \n",
      "Epoch 26/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3781 - loss: 0.0000e+00 \n",
      "Epoch 27/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3057 - loss: 0.0000e+00 \n",
      "Epoch 28/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2945 - loss: 0.0000e+00 \n",
      "Epoch 29/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - accuracy: 0.2892 - loss: 0.0000e+00  \n",
      "Epoch 30/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.2815 - loss: 0.0000e+00\n",
      "Epoch 31/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 0.3470 - loss: 0.0000e+00\n",
      "Epoch 32/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.2225 - loss: 0.0000e+00   \n",
      "Epoch 33/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.2549 - loss: 0.0000e+00   \n",
      "Epoch 34/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 0.2532 - loss: 0.0000e+00\n",
      "Epoch 35/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3288 - loss: 0.0000e+00 \n",
      "Epoch 36/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3220 - loss: 0.0000e+00 \n",
      "Epoch 37/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3526 - loss: 0.0000e+00 \n",
      "Epoch 38/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - accuracy: 0.3264 - loss: 0.0000e+00\n",
      "Epoch 39/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2642 - loss: 0.0000e+00   \n",
      "Epoch 40/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - accuracy: 0.2724 - loss: 0.0000e+00   \n",
      "Epoch 41/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.3877 - loss: 0.0000e+00\n",
      "Epoch 42/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - accuracy: 0.3188 - loss: 0.0000e+00   \n",
      "Epoch 43/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.2934 - loss: 0.0000e+00   \n",
      "Epoch 44/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.2563 - loss: 0.0000e+00\n",
      "Epoch 45/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.3134 - loss: 0.0000e+00\n",
      "Epoch 46/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - accuracy: 0.3285 - loss: 0.0000e+00\n",
      "Epoch 47/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - accuracy: 0.2897 - loss: 0.0000e+00   \n",
      "Epoch 48/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.3186 - loss: 0.0000e+00\n",
      "Epoch 49/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - accuracy: 0.2942 - loss: 0.0000e+00\n",
      "Epoch 50/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - accuracy: 0.3086 - loss: 0.0000e+00\n",
      "Epoch 51/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - accuracy: 0.2551 - loss: 0.0000e+00\n",
      "Epoch 52/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.3240 - loss: 0.0000e+00\n",
      "Epoch 53/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - accuracy: 0.2908 - loss: 0.0000e+00\n",
      "Epoch 54/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2806 - loss: 0.0000e+00 \n",
      "Epoch 55/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.2831 - loss: 0.0000e+00   \n",
      "Epoch 56/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3711 - loss: 0.0000e+00\n",
      "Epoch 57/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2481 - loss: 0.0000e+00 \n",
      "Epoch 58/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2926 - loss: 0.0000e+00 \n",
      "Epoch 59/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3003 - loss: 0.0000e+00   \n",
      "Epoch 60/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - accuracy: 0.2941 - loss: 0.0000e+00\n",
      "Epoch 61/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - accuracy: 0.2874 - loss: 0.0000e+00\n",
      "Epoch 62/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2653 - loss: 0.0000e+00     \n",
      "Epoch 63/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - accuracy: 0.3397 - loss: 0.0000e+00\n",
      "Epoch 64/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.3263 - loss: 0.0000e+00   \n",
      "Epoch 65/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.3019 - loss: 0.0000e+00\n",
      "Epoch 66/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2729 - loss: 0.0000e+00 \n",
      "Epoch 67/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3265 - loss: 0.0000e+00 \n",
      "Epoch 68/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - accuracy: 0.3362 - loss: 0.0000e+00\n",
      "Epoch 69/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3036 - loss: 0.0000e+00 \n",
      "Epoch 70/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3349 - loss: 0.0000e+00 \n",
      "Epoch 71/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - accuracy: 0.3219 - loss: 0.0000e+00\n",
      "Epoch 72/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.2902 - loss: 0.0000e+00   \n",
      "Epoch 73/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 0.3088 - loss: 0.0000e+00   \n",
      "Epoch 74/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - accuracy: 0.3477 - loss: 0.0000e+00\n",
      "Epoch 75/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2907 - loss: 0.0000e+00 \n",
      "Epoch 76/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.2624 - loss: 0.0000e+00   \n",
      "Epoch 77/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2874 - loss: 0.0000e+00     \n",
      "Epoch 78/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.3822 - loss: 0.0000e+00\n",
      "Epoch 79/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 0.3166 - loss: 0.0000e+00   \n",
      "Epoch 80/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - accuracy: 0.2334 - loss: 0.0000e+00   \n",
      "Epoch 81/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - accuracy: 0.3373 - loss: 0.0000e+00\n",
      "Epoch 82/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 0.3120 - loss: 0.0000e+00\n",
      "Epoch 83/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - accuracy: 0.2702 - loss: 0.0000e+00   \n",
      "Epoch 84/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - accuracy: 0.3682 - loss: 0.0000e+00\n",
      "Epoch 85/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - accuracy: 0.2491 - loss: 0.0000e+00  \n",
      "Epoch 86/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2838 - loss: 0.0000e+00 \n",
      "Epoch 87/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - accuracy: 0.3497 - loss: 0.0000e+00\n",
      "Epoch 88/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3091 - loss: 0.0000e+00     \n",
      "Epoch 89/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - accuracy: 0.3617 - loss: 0.0000e+00\n",
      "Epoch 90/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - accuracy: 0.3633 - loss: 0.0000e+00\n",
      "Epoch 91/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - accuracy: 0.2721 - loss: 0.0000e+00\n",
      "Epoch 92/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - accuracy: 0.3352 - loss: 0.0000e+00\n",
      "Epoch 93/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - accuracy: 0.2803 - loss: 0.0000e+00\n",
      "Epoch 94/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.3124 - loss: 0.0000e+00\n",
      "Epoch 95/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.2497 - loss: 0.0000e+00\n",
      "Epoch 96/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.3193 - loss: 0.0000e+00\n",
      "Epoch 97/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.3769 - loss: 0.0000e+00\n",
      "Epoch 98/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2697 - loss: 0.0000e+00\n",
      "Epoch 99/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - accuracy: 0.3340 - loss: 0.0000e+00\n",
      "Epoch 100/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.3087 - loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1fc3523bd40>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(x_train,y_train,batch_size=3,epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001FC38828860> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred=ann.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43333333333333335\n"
     ]
    }
   ],
   "source": [
    "cm=confusion_matrix(y_test,y_pred)\n",
    "acc=accuracy_score(y_test,y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1fc367133b0>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "disp=ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
